{
 "metadata": {
  "name": "",
  "signature": "sha256:c706092a97c7c2458bf41cc2c713f152f7dc0bdcb2b136e4f09a98ecd98c2e3f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Going deep"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notebook tries to help you go deep with your neural net. To do so, one cannot simply increase the number of convolutional layers at will. It is important that the layers have a sufficiently high learning capacity while they should cover approximately 100% of the incoming image ([Xudong Cao 2015](https://kaggle2.blob.core.windows.net/forum-message-attachments/69182/2287/A%20practical%20theory%20for%20designing%20very%20deep%20convolutional%20neural%20networks.pdf?sv=2012-02-12&se=2015-04-19T12%3A13%3A19Z&sr=b&sp=r&sig=xXaPwlkUZjIUxRyVebSNkX9viGgDPNHHpCXJRbokxUQ%3D)). To make it easier for the user to "
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Imports"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# -*- coding: utf-8 -*-\n",
      "from __future__ import division\n",
      "from copy import deepcopy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import theano\n",
      "import theano.tensor as T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from netz.layers import InputLayer, DenseLayer, OutputLayer, Conv2DLayer, MaxPool2DLayer, DropoutLayer\n",
      "from netz.neuralnet import NeuralNet\n",
      "from netz.costfunctions import mse, crossentropy\n",
      "from netz.nonlinearities import rectify\n",
      "from netz.updaters import Momentum, Nesterov, SGD\n",
      "from netz.visualize import plot_loss, plot_conv_weights, plot_conv_activity, plot_occlusion"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Make sure you have the MNIST data set ready. You can get it here: http://www.kaggle.com/c/digit-recognizer/data."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Load data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv('../data/mnist.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = df.values[:, 0]\n",
      "X = df.values[:, 1:] / 255"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = X.astype(theano.config.floatX)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = (X - X.mean()) / X.std()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X2D = X.reshape(-1, 1, 28, 28)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Useful information when going deep"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is generally a good idea to use small filter sizes for your convolutional layers, generally <b>3x3</b>. The reason for this is that this allows to cover the same receptive field of the image while using less parameters that would be required if a larger filter size were used. Moreover, deeper stacks of convolutional layers are more expressive (see [here](http://cs231n.github.io/convolutional-networks/) for more)."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "A shallow net"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "layers1 = [InputLayer(),\n",
      "           Conv2DLayer(16, (3, 3), nonlinearity=rectify),\n",
      "           MaxPool2DLayer(ds=(2, 2)),\n",
      "           Conv2DLayer(32, (3, 3), nonlinearity=rectify),\n",
      "           Conv2DLayer(32, (3, 3), nonlinearity=rectify),\n",
      "           MaxPool2DLayer(),\n",
      "           Conv2DLayer(32, (3, 3), nonlinearity=rectify),\n",
      "           DropoutLayer(p=0.5),\n",
      "           DenseLayer(100, nonlinearity=rectify),\n",
      "           DenseLayer(100, nonlinearity=rectify),\n",
      "           OutputLayer()]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net1 = NeuralNet(layers=layers1, updater=Nesterov(), verbose=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net1.initialize(X2D, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "# Neural Network with 63306 learnable parameters\n",
        "\n",
        "\n",
        "## Layer information\n",
        "| name       | size     |   total |   cap. Y [%] |   cap. X [%] |   cov. Y [%] |   cov. X [%] |\n",
        "|:-----------|:---------|--------:|-------------:|-------------:|-------------:|-------------:|\n",
        "| input0     | 1x28x28  |     784 |       100.00 |       100.00 |       100.00 |       100.00 |\n",
        "| conv2d0    | 16x26x26 |   10816 |       100.00 |       100.00 |        10.71 |        10.71 |\n",
        "| maxpool2d0 | 16x13x13 |    2704 |       100.00 |       100.00 |        10.71 |        10.71 |\n",
        "| conv2d1    | 32x11x11 |    3872 |        85.71 |        85.71 |        25.00 |        25.00 |\n",
        "| conv2d2    | 32x9x9   |    2592 |        54.55 |        54.55 |        39.29 |        39.29 |\n",
        "| maxpool2d1 | 32x5x5   |     800 |        54.55 |        54.55 |        39.29 |        39.29 |\n",
        "| conv2d3    | 32x3x3   |     288 |        63.16 |        63.16 |        67.86 |        67.86 |\n",
        "| dropout0   | 32x3x3   |     288 |       100.00 |       100.00 |       100.00 |       100.00 |\n",
        "| dense0     | 100      |     100 |       100.00 |       100.00 |       100.00 |       100.00 |\n",
        "| dense1     | 100      |     100 |       100.00 |       100.00 |       100.00 |       100.00 |\n",
        "| output0    | 10       |      10 |       100.00 |       100.00 |       100.00 |       100.00 |\n",
        "\n",
        "Explanation\n",
        "    X, Y:    image dimensions\n",
        "    cap.:    learning capacity\n",
        "    cov.:    coverage of image\n",
        "    \u001b[35mmagenta\u001b[0m: capacity too low (<1/6)\n",
        "    \u001b[36mcyan\u001b[0m:    image coverage too high (>100%)\n",
        "    \u001b[31mred\u001b[0m:     capacity too low and coverage too high\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This net is fine. The capacity never falls below 1/6, which would be 16.7%, and the coverage of the image never exceeds 100%. However, this net is not very deep, so let's try to go deeper.\n",
      "\n",
      "What we also see is the role of max pooling. If we look at 'maxpool2d1', after this layer, the capacity of the net is increased. Max pooling thus helps to increase capacity should it dip too low. However, max pooling also significantly increases the coverage of the image. So if we use max pooling too often, the coverage will quickly exceed 100% and we cannot go sufficiently deep."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Not enough max poolin"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "layers2 = [\n",
      "    InputLayer(),\n",
      "    Conv2DLayer(16, (3, 3), nonlinearity=rectify),\n",
      "    Conv2DLayer(16, (3, 3), nonlinearity=rectify),\n",
      "    Conv2DLayer(16, (3, 3), nonlinearity=rectify),\n",
      "    Conv2DLayer(16, (3, 3), nonlinearity=rectify),\n",
      "    Conv2DLayer(16, (3, 3), nonlinearity=rectify),\n",
      "    Conv2DLayer(16, (3, 3), nonlinearity=rectify),\n",
      "    Conv2DLayer(16, (3, 3), nonlinearity=rectify),\n",
      "    Conv2DLayer(16, (3, 3), nonlinearity=rectify),\n",
      "    Conv2DLayer(16, (3, 3), nonlinearity=rectify),\n",
      "    Conv2DLayer(16, (3, 3), nonlinearity=rectify),\n",
      "    Conv2DLayer(16, (3, 3), nonlinearity=rectify),\n",
      "    Conv2DLayer(16, (3, 3), nonlinearity=rectify),\n",
      "    Conv2DLayer(16, (3, 3), nonlinearity=rectify),\n",
      "    DenseLayer(100, nonlinearity=rectify),\n",
      "    DenseLayer(100, nonlinearity=rectify),\n",
      "    OutputLayer()\n",
      "]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net2 = NeuralNet(layers=layers2, updater=Nesterov(), verbose=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net2.initialize(X2D, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "# Neural Network with 45610 learnable parameters\n",
        "\n",
        "\n",
        "## Layer information\n",
        "| name     | size     |   total |   cap. Y [%] |   cap. X [%] |   cov. Y [%] |   cov. X [%] |\n",
        "|:---------|:---------|--------:|-------------:|-------------:|-------------:|-------------:|\n",
        "| input0   | 1x28x28  |     784 |       100.00 |       100.00 |       100.00 |       100.00 |\n",
        "| conv2d0  | 16x26x26 |   10816 |       100.00 |       100.00 |        10.71 |        10.71 |\n",
        "| conv2d1  | 16x24x24 |    9216 |        60.00 |        60.00 |        17.86 |        17.86 |\n",
        "| conv2d2  | 16x22x22 |    7744 |        42.86 |        42.86 |        25.00 |        25.00 |\n",
        "| conv2d3  | 16x20x20 |    6400 |        33.33 |        33.33 |        32.14 |        32.14 |\n",
        "| conv2d4  | 16x18x18 |    5184 |        27.27 |        27.27 |        39.29 |        39.29 |\n",
        "| conv2d5  | 16x16x16 |    4096 |        23.08 |        23.08 |        46.43 |        46.43 |\n",
        "| conv2d6  | 16x14x14 |    3136 |        20.00 |        20.00 |        53.57 |        53.57 |\n",
        "| conv2d7  | 16x12x12 |    2304 |        17.65 |        17.65 |        60.71 |        60.71 |\n",
        "| \u001b[35mconv2d8\u001b[0m  | 16x10x10 |    1600 |        15.79 |        15.79 |        67.86 |        67.86 |\n",
        "| \u001b[35mconv2d9\u001b[0m  | 16x8x8   |    1024 |        14.29 |        14.29 |        75.00 |        75.00 |\n",
        "| \u001b[35mconv2d10\u001b[0m | 16x6x6   |     576 |        13.04 |        13.04 |        82.14 |        82.14 |\n",
        "| \u001b[35mconv2d11\u001b[0m | 16x4x4   |     256 |        12.00 |        12.00 |        89.29 |        89.29 |\n",
        "| \u001b[35mconv2d12\u001b[0m | 16x2x2   |      64 |        11.11 |        11.11 |        96.43 |        96.43 |\n",
        "| dense0   | 100      |     100 |       100.00 |       100.00 |       100.00 |       100.00 |\n",
        "| dense1   | 100      |     100 |       100.00 |       100.00 |       100.00 |       100.00 |\n",
        "| output0  | 10       |      10 |       100.00 |       100.00 |       100.00 |       100.00 |\n",
        "\n",
        "Explanation\n",
        "    X, Y:    image dimensions\n",
        "    cap.:    learning capacity\n",
        "    cov.:    coverage of image\n",
        "    \u001b[35mmagenta\u001b[0m: capacity too low (<1/6)\n",
        "    \u001b[36mcyan\u001b[0m:    image coverage too high (>100%)\n",
        "    \u001b[31mred\u001b[0m:     capacity too low and coverage too high\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we have a very deep net but we have a problem: The lack of max pooling layers means that the capacity of the net dips below 16.7%. We need to find a better solution."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Too much max pooling"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "layers3 = [\n",
      "    InputLayer(),\n",
      "    Conv2DLayer(16, (3, 3), nonlinearity=rectify),\n",
      "    Conv2DLayer(16, (3, 3), nonlinearity=rectify),\n",
      "    MaxPool2DLayer(ds=(4, 4)),\n",
      "    Conv2DLayer(16, (3, 3), nonlinearity=rectify),\n",
      "    Conv2DLayer(16, (3, 3), nonlinearity=rectify),\n",
      "    MaxPool2DLayer(ds=(2, 2)),\n",
      "    Conv2DLayer(16, (3, 3), nonlinearity=rectify),\n",
      "    Conv2DLayer(16, (3, 3), nonlinearity=rectify),\n",
      "    MaxPool2DLayer(ds=(2, 2)),\n",
      "    Conv2DLayer(16, (3, 3), nonlinearity=rectify),\n",
      "    Conv2DLayer(16, (3, 3), nonlinearity=rectify),\n",
      "    MaxPool2DLayer(ds=(2, 2)),\n",
      "    DenseLayer(100, nonlinearity=rectify),\n",
      "    DenseLayer(100, nonlinearity=rectify),\n",
      "    OutputLayer()\n",
      "]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net3 = NeuralNet(layers=layers3, updater=Nesterov(), verbose=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net3.initialize(X2D, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "# Neural Network with 34010 learnable parameters\n",
        "\n",
        "\n",
        "## Layer information\n",
        "| name       | size     |   total |   cap. Y [%] |   cap. X [%] |   cov. Y [%] |   cov. X [%] |\n",
        "|:-----------|:---------|--------:|-------------:|-------------:|-------------:|-------------:|\n",
        "| input0     | 1x28x28  |     784 |       100.00 |       100.00 |       100.00 |       100.00 |\n",
        "| conv2d0    | 16x26x26 |   10816 |       100.00 |       100.00 |        10.71 |        10.71 |\n",
        "| conv2d1    | 16x24x24 |    9216 |        60.00 |        60.00 |        17.86 |        17.86 |\n",
        "| maxpool2d0 | 16x6x6   |     576 |        60.00 |        60.00 |        17.86 |        17.86 |\n",
        "| conv2d2    | 16x4x4   |     256 |        92.31 |        92.31 |        46.43 |        46.43 |\n",
        "| conv2d3    | 16x2x2   |      64 |        57.14 |        57.14 |        75.00 |        75.00 |\n",
        "| maxpool2d1 | 16x1x1   |      16 |        57.14 |        57.14 |        75.00 |        75.00 |\n",
        "| \u001b[36mconv2d4\u001b[0m    | 16x-1x-1 |      16 |        64.86 |        64.86 |       132.14 |       132.14 |\n",
        "| \u001b[36mconv2d5\u001b[0m    | 16x-3x-3 |     144 |        45.28 |        45.28 |       189.29 |       189.29 |\n",
        "| \u001b[36mmaxpool2d2\u001b[0m | 16x-1x-1 |      16 |        45.28 |        45.28 |       189.29 |       189.29 |\n",
        "| \u001b[36mconv2d6\u001b[0m    | 16x-3x-3 |     144 |        56.47 |        56.47 |       303.57 |       303.57 |\n",
        "| \u001b[36mconv2d7\u001b[0m    | 16x-5x-5 |     400 |        41.03 |        41.03 |       417.86 |       417.86 |\n",
        "| \u001b[36mmaxpool2d3\u001b[0m | 16x-2x-2 |      64 |        41.03 |        41.03 |       417.86 |       417.86 |\n",
        "| dense0     | 100      |     100 |       100.00 |       100.00 |       100.00 |       100.00 |\n",
        "| dense1     | 100      |     100 |       100.00 |       100.00 |       100.00 |       100.00 |\n",
        "| output0    | 10       |      10 |       100.00 |       100.00 |       100.00 |       100.00 |\n",
        "\n",
        "Explanation\n",
        "    X, Y:    image dimensions\n",
        "    cap.:    learning capacity\n",
        "    cov.:    coverage of image\n",
        "    \u001b[35mmagenta\u001b[0m: capacity too low (<1/6)\n",
        "    \u001b[36mcyan\u001b[0m:    image coverage too high (>100%)\n",
        "    \u001b[31mred\u001b[0m:     capacity too low and coverage too high\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This net uses too much max pooling for too small an image. The later layers, colored in cyan, would cover more than 100% of the image. As you can see, that would lead to negative image sizes for our net. Be aware though that if you use padding on the image, the image sizes might be positive while the coverage still exceeds 100%. So having a positive image size is not sufficient for coverage to be sufficiently low.\n",
      "\n",
      "Anyways, this solution thus does not work either, we have to find a better one."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "A good compromise"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "layers4 = [\n",
      "    InputLayer(),\n",
      "    Conv2DLayer(16, (3, 3), nonlinearity=rectify),\n",
      "    MaxPool2DLayer(ds=(2, 2)),\n",
      "    Conv2DLayer(32, (3, 3), nonlinearity=rectify),\n",
      "    Conv2DLayer(32, (3, 3), nonlinearity=rectify),\n",
      "    Conv2DLayer(64, (3, 3), nonlinearity=rectify),\n",
      "    Conv2DLayer(64, (3, 3), nonlinearity=rectify),\n",
      "    Conv2DLayer(128, (3, 3), nonlinearity=rectify),\n",
      "    Conv2DLayer(128, (3, 3), nonlinearity=rectify),\n",
      "    DenseLayer(100, nonlinearity=rectify),\n",
      "    DenseLayer(100, nonlinearity=rectify),\n",
      "    OutputLayer()\n",
      "]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net4 = NeuralNet(layers=layers4, updater=Nesterov(), verbose=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net4.initialize(X2D, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "# Neural Network with 314922 learnable parameters\n",
        "\n",
        "\n",
        "## Layer information\n",
        "| name       | size     |   total |   cap. Y [%] |   cap. X [%] |   cov. Y [%] |   cov. X [%] |\n",
        "|:-----------|:---------|--------:|-------------:|-------------:|-------------:|-------------:|\n",
        "| input0     | 1x28x28  |     784 |       100.00 |       100.00 |       100.00 |       100.00 |\n",
        "| conv2d0    | 16x26x26 |   10816 |       100.00 |       100.00 |        10.71 |        10.71 |\n",
        "| maxpool2d0 | 16x13x13 |    2704 |       100.00 |       100.00 |        10.71 |        10.71 |\n",
        "| conv2d1    | 32x11x11 |    3872 |        85.71 |        85.71 |        25.00 |        25.00 |\n",
        "| conv2d2    | 32x9x9   |    2592 |        54.55 |        54.55 |        39.29 |        39.29 |\n",
        "| conv2d3    | 64x7x7   |    3136 |        40.00 |        40.00 |        53.57 |        53.57 |\n",
        "| conv2d4    | 64x5x5   |    1600 |        31.58 |        31.58 |        67.86 |        67.86 |\n",
        "| conv2d5    | 128x3x3  |    1152 |        26.09 |        26.09 |        82.14 |        82.14 |\n",
        "| conv2d6    | 128x1x1  |     128 |        22.22 |        22.22 |        96.43 |        96.43 |\n",
        "| dense0     | 100      |     100 |       100.00 |       100.00 |       100.00 |       100.00 |\n",
        "| dense1     | 100      |     100 |       100.00 |       100.00 |       100.00 |       100.00 |\n",
        "| output0    | 10       |      10 |       100.00 |       100.00 |       100.00 |       100.00 |\n",
        "\n",
        "Explanation\n",
        "    X, Y:    image dimensions\n",
        "    cap.:    learning capacity\n",
        "    cov.:    coverage of image\n",
        "    \u001b[35mmagenta\u001b[0m: capacity too low (<1/6)\n",
        "    \u001b[36mcyan\u001b[0m:    image coverage too high (>100%)\n",
        "    \u001b[31mred\u001b[0m:     capacity too low and coverage too high\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net4.fit(X2D, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "## Training Information\n",
        " Epoch | Train loss | Valid loss | Train/Val | Valid acc | Dur\n",
        "-------|------------|------------|-----------|-----------|------\n",
        "     0 |   0.760775 |   0.150348 |    5.060  |  0.9562   | 987.9s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     1 |   0.115425 |   0.110122 |    1.048  |  0.9641   | 991.5s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     2 |   0.074402 |   0.095273 |    0.781  |  0.9704   | 1373.6s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     3 |   0.055383 |   0.081217 |    0.682  |  0.9750   | 1395.3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     4 |   0.042681 |   0.079084 |    0.540  |  0.9789   | 1425.3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "NeuralNet(connection_pattern=None,\n",
        "     cost_function=<function crossentropy at 0x0000000016A34BA8>,\n",
        "     encoder=OneHotEncoder(categorical_features='all', dtype=dtype('int64'),\n",
        "       n_values='auto', sparse=False),\n",
        "     eval_size=0.2,\n",
        "     iterator=<nolearn.lasagne.BatchIterator object at 0x0000000016D00EB8>,\n",
        "     lambda2=None,\n",
        "     layers=[input0, conv2d0, maxpool2d0, conv2d1, conv2d2, conv2d3, conv2d4, conv2d5, conv2d6, dense0, dense1, output0],\n",
        "     recurrent=False, regression=False,\n",
        "     updater=<netz.updaters.Nesterov object at 0x000000002E413550>,\n",
        "     verbose=2)"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With seven convolutional layers, this network is rather deep, given the small image size. Yet the learning capacity is always suffiently large and never are more than 100% of the image covered. This could just be a good solution."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note 1: The MNIST images typically don't cover the whole of the 28x28 image size. Therefore, an image coverage of less than 100% is probably very acceptable. For other image data sets such as CIFAR or ImageNet, it is recommended to cover the whole image."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note 2: This analysis does not tell us how many feature maps (i.e. number of filters per convolutional layer) to use. Here we have to experiment with different values. Larger values mean that the network should learn more types of features but also increase the risk of overfitting. In general though, deeper layers (those farther down) should learn more complex features and should thus have more feature maps."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "More details"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is possible to get more information by increasing the verbosity level beyond 1."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net4.verbose = 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net4.initialize(X2D, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "# Neural Network with 314922 learnable parameters\n",
        "\n",
        "\n",
        "## Layer information\n",
        "name        size        total    cap. Y [%]    cap. X [%]    cov. Y [%]    cov. X [%]    filter Y    filter X    field Y    field X\n",
        "----------  --------  -------  ------------  ------------  ------------  ------------  ----------  ----------  ---------  ---------\n",
        "input0      1x28x28       784        100.00        100.00        100.00        100.00          28          28         28         28\n",
        "conv2d0     16x26x26    10816        100.00        100.00         10.71         10.71           3           3          3          3\n",
        "maxpool2d0  16x13x13     2704        100.00        100.00         10.71         10.71           3           3          3          3\n",
        "conv2d1     32x11x11     3872         85.71         85.71         25.00         25.00           6           6          7          7\n",
        "conv2d2     32x9x9       2592         54.55         54.55         39.29         39.29           6           6         11         11\n",
        "conv2d3     64x7x7       3136         40.00         40.00         53.57         53.57           6           6         15         15\n",
        "conv2d4     64x5x5       1600         31.58         31.58         67.86         67.86           6           6         19         19\n",
        "conv2d5     128x3x3      1152         26.09         26.09         82.14         82.14           6           6         23         23\n",
        "conv2d6     128x1x1       128         22.22         22.22         96.43         96.43           6           6         27         27\n",
        "dense0      100           100        100.00        100.00        100.00        100.00          28          28         28         28\n",
        "dense1      100           100        100.00        100.00        100.00        100.00          28          28         28         28\n",
        "output0     10             10        100.00        100.00        100.00        100.00          28          28         28         28\n",
        "\n",
        "Explanation\n",
        "    X, Y:    image dimensions\n",
        "    cap.:    learning capacity\n",
        "    cov.:    coverage of image\n",
        "    \u001b[35mmagenta\u001b[0m: capacity too low (<1/6)\n",
        "    \u001b[36mcyan\u001b[0m:    image coverage too high (>100%)\n",
        "    \u001b[31mred\u001b[0m:     capacity too low and coverage too high\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we get additional information about the real filter size of the convolutional layers, as well as their receptive field sizes. If the receptive field size grows too large compared to the real filter size, capacity dips too low. As receptive field size grows larger, more and more of the image is covered."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Caveat"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A caveat to the findings presented here is that capacity and coverage may not be calculated correctly if you use padding or strides other than 1 in the convolutional layers. Including this would make the calculation much more complicated. However, even if you want to use these parameters, the calculations shown here should not deviate too much and the results may still serve as a rough guideline."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}